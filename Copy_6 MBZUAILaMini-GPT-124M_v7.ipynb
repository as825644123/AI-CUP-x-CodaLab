{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xw42TinTd0sD",
    "outputId": "d77cc894-5b4e-45bd-a176-9b28c1925a7d"
   },
   "outputs": [],
   "source": [
    "# !pip install islab-opendeid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PCO35TUG1Dd"
   },
   "source": [
    "### import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zoh-ktTWx4az"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig, get_linear_schedule_with_warmup\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hUSHfpdtx4a5"
   },
   "outputs": [],
   "source": [
    "def set_torch_seed(seed = 0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benckmark = False\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_torch_seed()\n",
    "\n",
    "def read_file(path):\n",
    "    with open(path , 'r' , encoding = 'utf-8-sig') as fr:\n",
    "        return fr.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYrJwCe0G3dO"
   },
   "source": [
    "### 資料處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FG19J2gqx4a5",
    "outputId": "4e1d65c5-e6b7-43ac-eeed-6b9783d9a9b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process annotation file...\n",
      "annotation file done\n",
      "processing each medical file\n",
      "All medical file done\n",
      "write out to tsv format...\n",
      "tsv format dataset done\n",
      "process annotation file...\n",
      "annotation file done\n",
      "processing each medical file\n",
      "All medical file done\n",
      "write out to tsv format...\n",
      "tsv format dataset done\n"
     ]
    }
   ],
   "source": [
    "bos = '<|endoftext|>'\n",
    "eos = '<|END|>'\n",
    "pad = '<p>'\n",
    "ner = '\\n\\n####\\n\\n'\n",
    "special_tokens_dict = {'bos_token': bos,\n",
    "                       'eos_token': eos,\n",
    "                       'pad_token': pad,\n",
    "                       'sep_token': ner}\n",
    "\n",
    "def process_annotation_file(lines):\n",
    "    '''\n",
    "    處理anwser.txt 標註檔案\n",
    "\n",
    "    output:annotation dicitonary\n",
    "    '''\n",
    "    print(\"process annotation file...\")\n",
    "    entity_dict = {}\n",
    "    for line in lines:\n",
    "        '''\n",
    "        # '\\n' 分行\n",
    "        # '\\t' 分詞\n",
    "        '''\n",
    "        \n",
    "        items = line.strip('\\n').split('\\t')\n",
    "        if len(items) == 5:\n",
    "            item_dict = {\n",
    "                'phi' : items[1],\n",
    "                'st_idx' : int(items[2]),\n",
    "                'ed_idx' : int(items[3]),\n",
    "                'entity' : items[4],\n",
    "            }\n",
    "        elif len(items) == 6:\n",
    "            item_dict = {\n",
    "                'phi' : items[1],\n",
    "                'st_idx' : int(items[2]),\n",
    "                'ed_idx' : int(items[3]),\n",
    "                'entity' : items[4],\n",
    "                'normalize_time' : items[5],\n",
    "            }\n",
    "        if items[0] not in entity_dict:\n",
    "            entity_dict[items[0]] = [item_dict]\n",
    "        else:\n",
    "            entity_dict[items[0]].append(item_dict)\n",
    "    print(\"annotation file done\")\n",
    "    return entity_dict\n",
    "\n",
    "def process_medical_report(txt_name, medical_report_folder, annos_dict, special_tokens_dict):\n",
    "    '''\n",
    "    處理單個病理報告\n",
    "\n",
    "    output : 處理完的 sequence pairs\n",
    "    '''\n",
    "    file_name = txt_name + '.txt'\n",
    "    sents = read_file(os.path.join(medical_report_folder, file_name))\n",
    "    article = \"\".join(sents)\n",
    "\n",
    "    bounary , item_idx , temp_seq , seq_pairs = 0 , 0 , \"\" , []\n",
    "    new_line_idx = 0\n",
    "    for w_idx, word in enumerate(article):\n",
    "        \n",
    "        # 重要!!!\n",
    "        if word == '\"':\n",
    "            article = article[:w_idx] + ' ' + article[w_idx + 1:]\n",
    "\n",
    "        if w_idx == annos_dict[txt_name][item_idx]['st_idx']:\n",
    "            phi_key = annos_dict[txt_name][item_idx]['phi']\n",
    "            phi_value = annos_dict[txt_name][item_idx]['entity']\n",
    "            \n",
    "            if 'normalize_time' in annos_dict[txt_name][item_idx]:\n",
    "                temp_seq += f\"{phi_key} QAQ {phi_value}=>{annos_dict[txt_name][item_idx]['normalize_time']}   \"\n",
    "            else:\n",
    "                temp_seq += f\"{phi_key} QAQ {phi_value}   \"\n",
    "                    \n",
    "            if item_idx == len(annos_dict[txt_name]) - 1:\n",
    "                # 重要!!!\n",
    "                item_idx = 0\n",
    "                \n",
    "                continue\n",
    "            item_idx += 1\n",
    "        \n",
    "        if word == '\\n':\n",
    "            new_line_idx = w_idx + 1\n",
    "            if article[bounary:new_line_idx] == '\\n':\n",
    "                \n",
    "                # 重要!!!\n",
    "                bounary = new_line_idx\n",
    "                \n",
    "                continue\n",
    "            if temp_seq == \"\":\n",
    "                # bounary = new_line_idx\n",
    "                # continue\n",
    "                temp_seq = \"PHI QAQ Null\"\n",
    "            sentence = article[bounary:new_line_idx].strip().replace('\\t' , ' ')\n",
    "            temp_seq = temp_seq.strip('\\\\n')\n",
    "            \n",
    "            # 重要!!!\n",
    "            # seq_pair = f\"{txt_name}\\t{bounary}\\t{sentence}\\t{temp_seq}\\n\"\n",
    "            seq_pair = f\"{bounary}\\t{sentence}\\t{temp_seq}\\n\"\n",
    "            \n",
    "            # seq_pair = f\"{txt_name}\\t{new_line_idx}\\t{sentence}\\t{temp_seq}\\n\"\n",
    "            ## seq_pair = special_tokens_dict['bos_token'] + article[bounary:new_line_idx] + special_tokens_dict['sep_token'] + temp_seq + special_tokens_dict['eos_token']\n",
    "            bounary = new_line_idx\n",
    "            seq_pairs.append(seq_pair)\n",
    "            temp_seq = \"\"\n",
    "    return seq_pairs\n",
    "\n",
    "def generate_annotated_medical_report_parallel(anno_file_path, medical_report_folder , tsv_output_path , num_processes = 4):\n",
    "    '''\n",
    "    呼叫上面的兩個function\n",
    "    處理全部的病理報告和標記檔案\n",
    "\n",
    "    output : 全部的 sequence pairs\n",
    "    '''\n",
    "    anno_lines = read_file(anno_file_path)\n",
    "    annos_dict = process_annotation_file(anno_lines)\n",
    "    txt_names = list(annos_dict.keys())\n",
    "\n",
    "    print(\"processing each medical file\")\n",
    "\n",
    "    all_seq_pairs = []\n",
    "    for txt_name in txt_names:\n",
    "        all_seq_pairs.extend(process_medical_report(txt_name, medical_report_folder, annos_dict, special_tokens_dict))\n",
    "    # print(all_seq_pairs[:10])\n",
    "    print(\"All medical file done\")\n",
    "    print(\"write out to tsv format...\")\n",
    "    with open(tsv_output_path , 'w' , encoding = 'utf-8') as fw:\n",
    "        for seq_pair in all_seq_pairs:\n",
    "            fw.write(seq_pair)\n",
    "    print(\"tsv format dataset done\")\n",
    "    # return all_seq_pairs\n",
    "\n",
    "anno_info_path_First = r\"data/First_Phase_Release(Correction)/answer.txt\"\n",
    "report_folder_First = r\"data/First_Phase_Release(Correction)/First_Phase_Text_Dataset\"\n",
    "tsv_output_path_First = r\"data/First_Phase_Release(Correction)/train.tsv\"\n",
    "generate_annotated_medical_report_parallel(anno_info_path_First, report_folder_First, tsv_output_path_First, num_processes = 4)\n",
    "\n",
    "anno_info_path_Second = r\"data/Second_Phase_Dataset/answer.txt\"\n",
    "report_folder_Second = r\"data/Second_Phase_Dataset/Second_Phase_Text_Dataset\"\n",
    "tsv_output_path_Second = r\"data/Second_Phase_Dataset/train.tsv\"\n",
    "generate_annotated_medical_report_parallel(anno_info_path_Second, report_folder_Second, tsv_output_path_Second, num_processes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_total = r\"data/trainTotal.tsv\"\n",
    "\n",
    "with open(tsv_output_path_First , 'r' , encoding = 'utf-8') as fw:\n",
    "    content1 = fw.read()\n",
    "\n",
    "with open(tsv_output_path_Second , 'r' , encoding = 'utf-8') as fw:\n",
    "    content2 = fw.read()\n",
    "\n",
    "merged_content = content1 + '\\n' + content2\n",
    "\n",
    "with open(training_data_total , 'w' , encoding = 'utf-8') as fw:\n",
    "    fw.write(merged_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process annotation file...\n",
      "annotation file done\n"
     ]
    }
   ],
   "source": [
    "anno_lines = read_file(anno_info_path_First)\n",
    "annos_dict = process_annotation_file(anno_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phi': 'MEDICALRECORD', 'st_idx': 1, 'ed_idx': 12, 'entity': '9324677.BOP'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annos_dict['100'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyorkVtCIAzl"
   },
   "source": [
    "### Read Tsv Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "3ab10d53358341c08bdb473b60a987ed",
      "04f5241d1ed74346a6e079f20b0e1c86",
      "15a75326cb3446639f6476175594f674",
      "a8d3a2563e93469282d2aa1254c8a709",
      "dd4aae35778245dcb85cc3bfaeeab2cb",
      "06a3d8b0210642098a789cabcd9fe946",
      "9c743c15b86d4f19834b933fe4147920",
      "f2baeb275db84ee2be09ad54cba4b557",
      "ebc555d2bdf542208af547b35f098e0f",
      "ed64e4b7931d4e80bd1b830e9ab4589a",
      "d6084e8cbf9e4afea588776c60058b44",
      "02fdb917569740c2a15ce78df9fe9f0d",
      "351429ff2f4d4f1185fed17d49c2df55",
      "29c3341b98ed45cebe9768a1cee61789",
      "240e4fbdac7a4783b7b1a265f827b8e6",
      "cd395bc5ef7347059cc3967f293e9cb4",
      "c34d081bc24a477ca2a9033fb5ac96e0",
      "0277cbac4f0744d0a2460ede86d1ad33",
      "1d8908777f5246b5b0a47708e7b92c2a",
      "f8c235594ea04894b7ae7045069b6b71",
      "2ed3fe215482424ca313941bf4999131",
      "847104cbfe6c447e8f3e6cf789c1860d",
      "e765ef2c16a244cbba8afd58f0b19bc1",
      "364c458247d3493eb836d163204e7c44",
      "138978af73d44cddb6b42165f50616a1",
      "bd858ddc900540d39319402f576a6146",
      "6a2e7073e6244df590aebaef7a22fcbc",
      "cc80bd4f3e9b40f7901387ffb92c9af2",
      "eb7955e3b9bd491d9a170a6410991603",
      "fa23352bc7864a38ab8c52ae1f8f15ca",
      "edd98b31b60f48d395a3b9f35e0cb15e",
      "5906da6ef4cb493fa69981791169ba6f",
      "d91b672aab19468a8f9ba084c9181705"
     ]
    },
    "id": "2qeh5TtuIASS",
    "outputId": "719aaf5d-e8f8-47d5-bbde-469134ca4165"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd211f93f6d4397bb0185b40278d19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a91fe051a64ce8bc9cf98a04b61ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9487874f4a8342fdbbfd4da9f15f0825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Features, Value\n",
    "\n",
    "dataset = load_dataset('csv', data_files = training_data_total, delimiter = '\\t',\n",
    "                       features = Features({\n",
    "                              'idx': Value('int64'),\n",
    "                              'content': Value('string'), 'label': Value('string')}),\n",
    "                              column_names=['idx', 'content', 'label'], keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['idx', 'content', 'label'],\n",
       "        num_rows: 78575\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ny9tkyPe4A11",
    "outputId": "ab80c764-bf83-4f3a-ae5e-a0dc9f12643c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['idx', 'content', 'label'],\n",
       "    num_rows: 78575\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 4344, 'content': 'Material received:', 'label': 'PHI QAQ Null'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1209]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giYNlCPI47j1",
    "outputId": "8ba11a51-50e4-4b68-f112-a7661d0a1b18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n1195 o\\n\\n1209\\n1210\\n\\n1270 x\\n\\n好像雙引號會出問題\"\\t \\n\"\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset['train']))\n",
    "\n",
    "'''\n",
    "1195 o\n",
    "\n",
    "1209\n",
    "1210\n",
    "\n",
    "1270 x\n",
    "\n",
    "好像雙引號會出問題\"\\t \\n\"\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlYrlTUH5HLD"
   },
   "source": [
    "### Dataloader Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "95f62323efb74a5fbc8eeea96fde205f",
      "53eb2f1db30643b892f2fb0de4e462e0",
      "771c433a517f4d5caefe3d1a5ab6dbd5",
      "699293e978ee4e03a29873ab1aa5584a",
      "9881ffc1fe1f4d42ad86a434de5630c3",
      "4583193cd4d2416f891d79e3f6574ae1",
      "74c075f1555c40c4acef391e7ebd607a",
      "262d64b395eb438e80749d5447043f6c",
      "477487bd5dd54a789eb3d8a421b848d2",
      "4131050ae1db4ec59e28043b263edee4",
      "35b763e2220d47f888dd532d929b91c1",
      "4d7d64eecd1c43c0b93df2b5580a3089",
      "541b410749e64a1898b689a71fdcd190",
      "a699553a035245faa229208847d769c1",
      "905fbcece64f4a44a16e0bc230212809",
      "fc9c2553ba8a48dd9a8a24ab58a3712c",
      "930ae3d226c84d39b7e99ba2094d13de",
      "6b4e1cd915dc4467a383f595c97428c9",
      "93839d2cb8eb47e98bde3cc6ea26be61",
      "c5a12d27ad8d4b928225fec745838bb8",
      "d03ce9716d884221828cdf8f522c7b23",
      "1c12b7a726904fd28f3722a73f8aed46",
      "7c8b111c35ed4795b299d8b4a9a677e9",
      "12c9de0d18844719ab9b1a19876c77e0",
      "3efa4f1535c04dc6853d08d760e53f10",
      "0c9d57ad1dfc458e9ddb25692f881976",
      "bc5c0b0bb22b46979526f4ee320f3154",
      "66f51dc7be3a453099a82a17731c136a",
      "9b5ca4c8b80e4b59a3ea6535c73449c5",
      "4c912f23ed4341e9bf76ca5d0b0d1c6d",
      "a17d608a377c4fe7803d7df82a2a1e4b",
      "114be4b208be40e0a17ddee4e046fb23",
      "3664935430614c24bd7f5c4e3b2e04c6"
     ]
    },
    "id": "l_P9L_j54FD1",
    "outputId": "c602b221-1694-4e66-ae11-6a34bc5450d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>: 50259\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "plm = \"MBZUAI/LaMini-GPT-124M\" #\"EleutherAI/pythi a-70m-deduped\"\n",
    "\n",
    "bos = '<|endoftext|>'\n",
    "eos = '<|END|>'\n",
    "pad = '<p>'\n",
    "sep ='\\n\\n####\\n\\n'\n",
    "\n",
    "special_tokens_dict = {'eos_token': eos, 'bos_token': bos, 'pad_token': pad, 'sep_token': sep}\n",
    "# special_tokens_dict = {'pad_token': pad, 'sep_token': sep}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(plm)\n",
    "tokenizer.padding_side = 'left'\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print(f\"{tokenizer.pad_token}: {tokenizer.pad_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 1,\n",
       " 'content': 'Episode No:  09F016547J',\n",
       " 'label': 'IDNUM QAQ 09F016547J   '}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset['train'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTest Region.\\n\\ninput_ids：\\n這是 tokenized 後的文本，\\n其中每個 token 被映射為相應的 token ID。\\n在 BERT 或其他 Transformer 模型中，\\n每個 token ID 將對應到模型的詞彙表中的一個索引。\\ninput_ids 是模型接受的主要輸入。\\n\\nattention_mask：\\n這是一個二進制的遮罩，\\n用於指示模型在進行 self-attention 計算時應該考慮還是忽略相應的位置。\\n如果某個位置是 padding 的，則對應的 attention mask 將為 0（忽略），否則為 1（考慮）。\\n這是為了確保模型不會在 padding 的位置上產生意外的注意力。\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Test Region.\n",
    "\n",
    "input_ids：\n",
    "這是 tokenized 後的文本，\n",
    "其中每個 token 被映射為相應的 token ID。\n",
    "在 BERT 或其他 Transformer 模型中，\n",
    "每個 token ID 將對應到模型的詞彙表中的一個索引。\n",
    "input_ids 是模型接受的主要輸入。\n",
    "\n",
    "attention_mask：\n",
    "這是一個二進制的遮罩，\n",
    "用於指示模型在進行 self-attention 計算時應該考慮還是忽略相應的位置。\n",
    "如果某個位置是 padding 的，則對應的 attention mask 將為 0（忽略），否則為 1（考慮）。\n",
    "這是為了確保模型不會在 padding 的位置上產生意外的注意力。\n",
    "'''\n",
    "\n",
    "# def collate_batch_with_prompt_template(batch, tokenizer, template = \"__CONTENT__\\n\\n####\\n\\n__LABEL__\", IGNORED_PAD_IDX = -100):\n",
    "#     # default template: {bos} {data['content']} {sep}\n",
    "#     return 0\n",
    "#     texts = [template.replace(\"__LABEL__\", data['label']).replace(\"__CONTENT__\", data['content']) for data in list(batch)]\n",
    "#     encoded_seq = tokenizer(texts, padding=True)\n",
    "    \n",
    "#     indexed_tks = torch.tensor(encoded_seq['input_ids'])\n",
    "#     attention_mask = torch.tensor(encoded_seq['attention_mask'])\n",
    "#     encoded_label = torch.tensor(encoded_seq['input_ids'])\n",
    "#     encoded_label[encoded_label == tokenizer.pad_token_id] = IGNORED_PAD_IDX\n",
    "    \n",
    "#     return indexed_tks, encoded_label, attention_mask\n",
    "\n",
    "# train_data = list(dataset['train'])\n",
    "# train_dataloader = DataLoader(train_data, batch_size=3, shuffle=False, collate_fn=lambda batch: collate_batch_with_prompt_template(batch, tokenizer))\n",
    "# train_dataloader_x = DataLoader(train_data, batch_size=3, shuffle=False)\n",
    "# titer = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n三個(batch_size)三個放一起，放在字典的value list裡面\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(type(train_dataloader))\n",
    "# print(type(train_dataloader_x))\n",
    "\n",
    "# print(\"---\" * 30)\n",
    "# for data in train_dataloader:\n",
    "#     print(data)\n",
    "#     break\n",
    "\n",
    "# print(\"---\" * 30)\n",
    "# for data in train_dataloader_x:\n",
    "#     print(data)\n",
    "#     break\n",
    "    \n",
    "'''\n",
    "三個(batch_size)三個放一起，放在字典的value list裡面\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWy3otmh5JQZ",
    "outputId": "0b4a0064-db03-41cd-cb2d-d91e3ff24f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n這部分將 train_dataloader 轉換為迭代器（titer），並使用 next(titer) 提取下一個資料批次。\\n批次包含三個部分：tks、labels 和 masks。tks 似乎是經過標記的輸入資料，而 labels 可能是相應的標籤。\\nprint(tks.shape) 印出 tks 的形狀。\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from islab.aicup import collate_batch_with_prompt_template\n",
    "\n",
    "train_data = list(dataset['train'])\n",
    "train_dataloader = DataLoader(train_data, batch_size=5, shuffle=False, collate_fn=lambda batch: collate_batch_with_prompt_template(batch, tokenizer))\n",
    "titer = iter(train_dataloader)\n",
    "tks, labels, masks= next(titer)\n",
    "print(tks.shape)\n",
    "next(iter(titer))\n",
    "\n",
    "'''\n",
    "這部分將 train_dataloader 轉換為迭代器（titer），並使用 next(titer) 提取下一個資料批次。\n",
    "批次包含三個部分：tks、labels 和 masks。tks 似乎是經過標記的輸入資料，而 labels 可能是相應的標籤。\n",
    "print(tks.shape) 印出 tks 的形狀。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c630kJKs5Tkh",
    "outputId": "366009ff-0b13-4591-c500-957c952602e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "------------------------------------------------------------------------------------------\n",
      "WARNING:tensorflow:From C:\\Users\\longy\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "9364819.RAN\\nMINTANIA, JEFFRY \n",
      "\n",
      "####\n",
      "\n",
      " ID: 9364819.RAN\\nNAME: MINTANIA, JEFFRY\n",
      "------------------------------------------------------------------------------------------\n",
      "<p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p><p>This is a sentence \n",
      "\n",
      "####\n",
      "\n",
      " PHI: NULL\n"
     ]
    }
   ],
   "source": [
    "results = tokenizer(\n",
    "    [f\"9364819.RAN\\\\nMINTANIA, JEFFRY {sep} ID: 9364819.RAN\\\\nNAME: MINTANIA, JEFFRY\",\n",
    "     f\"This is a sentence {sep} PHI: NULL\"],\n",
    "    padding=True\n",
    ")\n",
    "print(results['attention_mask'][0])\n",
    "print(results['attention_mask'][1])\n",
    "print(\"---\" * 30)\n",
    "print(tokenizer.decode(results['input_ids'][0]))\n",
    "print(\"---\" * 30)\n",
    "print(tokenizer.decode(results['input_ids'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QzPXEH15bLQ"
   },
   "source": [
    "### DataLoader For training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2bjnm09N5WuO"
   },
   "outputs": [],
   "source": [
    "from islab.aicup import OpenDeidBatchSampler\n",
    "\n",
    "# BATCH_SIZE = 6\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "bucket_train_dataloader = DataLoader(train_data,\n",
    "                                     batch_sampler=OpenDeidBatchSampler(train_data, BATCH_SIZE),\n",
    "                                     collate_fn=lambda batch: collate_batch_with_prompt_template(batch, tokenizer),\n",
    "                                     pin_memory=True)\n",
    "# , num_workers=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550,
     "referenced_widgets": [
      "fd8483f4d5f541ca89bcdb48e83aa262",
      "fcd1dd3df93040578f33ba79cbc79464",
      "c47491ab567c4aa6ad6da05329d5b570",
      "f76695b96069401e938c52e75430ea1e",
      "f704f11641774603b4d5319580fbb994",
      "d7f1fd5dafe143d58b383865f2520892",
      "a250ec3f4bb043688fe9a74a85ae622e",
      "fc83a2f4b0964878a6c3a77018288a46",
      "57b70738c47d4c46b11ec8d9f3da8002",
      "7d4e0e0b68b14aee9ba6060c88e8fbe7",
      "cee85f4100e04283b6276653174ae667",
      "8d44ecffa2f045f0bab7d5c1f3722ac1",
      "aa22a2d4c9254284ab8e20e85cf6a1dd",
      "99d41ec930c84fb485167dce8d6453d4",
      "8fdb40e1334a407482b3e023a593d697",
      "48849553f92a403e81a32572edadf54b",
      "620547130fe8427587389ffd8605242e",
      "35e624622fc7427e9e3e9ce06ff69b13",
      "82d3f122e8344078b2f59c8992d318d1",
      "dc45d04b5f8b4e84ae99b5406a8a8d8d",
      "716ec33c9d4444468922a4515c861bfd",
      "0b1e56e88a584720a0a3491ac11050bb"
     ]
    },
    "id": "pMTzysvI5dkO",
    "outputId": "9dcd2bed-7d02-48bd-d503-e070d88512e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50258, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the model config to which we add the special tokens\n",
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(plm,\n",
    "                                    bos_token_id=tokenizer.bos_token_id,\n",
    "                                    eos_token_id=tokenizer.eos_token_id,\n",
    "                                    pad_token_id=tokenizer.pad_token_id,\n",
    "                                    sep_token_id=tokenizer.sep_token_id,\n",
    "                                    output_hidden_states=False)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(plm, config=config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0Mp5uYw5hNJ",
    "outputId": "c5fd316b-a601-4cb0-83b6-5776978cb157"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50261, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50261, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "EPOCHS = 30 # CHANGE TO THE NUMBER OF EPOCHS YOU WANT\n",
    "optimizer = AdamW(model.parameters(),lr=3e-5) # YOU CAN ADJUST LEARNING RATE\n",
    "# optimizer = AdamW(model.parameters(),lr=3e-5)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_text(model, tokenizer, text, n_words=100):\n",
    "    '''\n",
    "    input : model, tokenizer, text(句子 string), n_words(生成字數限制)\n",
    "    output : 模型預測結果 (string)\n",
    "    '''\n",
    "    model.eval()\n",
    "    text = tokenizer.encode(text)\n",
    "    inputs, past_key_values = torch.tensor([text]).to(device), None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_words):\n",
    "            out = model(inputs, past_key_values=past_key_values)\n",
    "            logits = out.logits\n",
    "            past_key_values = out.past_key_values\n",
    "            log_probs = F.softmax(logits[:, -1], dim=-1)\n",
    "            inputs = torch.multinomial(log_probs, 1)\n",
    "            text.append(inputs.item())\n",
    "            if tokenizer.decode(inputs.item()) == eos:\n",
    "                break\n",
    "\n",
    "    return tokenizer.decode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d_A3L0h65q8l",
    "outputId": "d99a80d8-8bc0-49fb-d449-016e29cdae63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/30 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "# 模型儲存資料夾名稱\n",
    "model_name = \"data/First_Phase_Release(Correction)/models/GPT2LMHeadModel\"\n",
    "# 模型儲存路徑\n",
    "model_dir = f\"{model_name}\"\n",
    "\n",
    "accumulation_steps = 2\n",
    "if not os.path.isdir(model_dir):\n",
    "     os.mkdir(model_dir)\n",
    "min_loss = float('inf')  # 使用 float('inf') 表示正無窮\n",
    "model = model.to(device)\n",
    "\n",
    "# 如果有多個 GPU，將模型擴展到多個 GPU 上\n",
    "if torch.cuda.device_count() > 1:\n",
    "    #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "predict_text = special_tokens_dict['bos_token'] + \"MANILDRA  NSW  2865\"\n",
    "\n",
    "# 模型訓練開始\n",
    "for epoch in trange(EPOCHS, desc=\"Epoch\"):\n",
    "    #print('epoch=', epoch)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, (seqs, labels, masks) in enumerate(tqdm(bucket_train_dataloader)):\n",
    "        seqs = seqs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        model.zero_grad()\n",
    "        outputs = model(seqs, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        loss = loss.mean()\n",
    "        total_loss += loss.item()\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward()\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "        #del seqs\n",
    "        #del labels\n",
    "        #del masks\n",
    "    avg_train_loss = total_loss / len(bucket_train_dataloader)\n",
    "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
    "    print(sample_text(model, tokenizer, text=predict_text))\n",
    "    torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': min_loss,\n",
    "                }, os.path.join(model_dir , 'GPT2LMHeadModel_Finial.pt'))\n",
    "    if avg_train_loss < min_loss:\n",
    "        min_loss = avg_train_loss\n",
    "        torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': min_loss,\n",
    "                }, os.path.join(model_dir , 'GPT2LMHeadModel_best.pt'))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When training crashes, call the last model to continue unfinished training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "# 模型儲存資料夾名稱\n",
    "model_name = \"data/First_Phase_Release(Correction)/models/GPT2LMHeadModel\"\n",
    "# 模型儲存路徑\n",
    "model_dir = f\"{model_name}\"\n",
    "\n",
    "checkpoint = torch.load(os.path.join(model_dir , 'GPT2LMHeadModel_best.pt'))\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epo = checkpoint['epoch']\n",
    "min_loss = checkpoint['loss']\n",
    "model = model.to(device)\n",
    "\n",
    "accumulation_steps = 2\n",
    "if not os.path.isdir(model_dir):\n",
    "     os.mkdir(model_dir)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# 如果有多個 GPU，將模型擴展到多個 GPU 上\n",
    "if torch.cuda.device_count() > 1:\n",
    "    #print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "predict_text = special_tokens_dict['bos_token'] + \"MANILDRA  NSW  2865\"\n",
    "\n",
    "# 模型訓練開始\n",
    "for epoch in trange(EPOCHS-epo, desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, (seqs, labels, masks) in enumerate(tqdm(bucket_train_dataloader)):\n",
    "        seqs = seqs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        model.zero_grad()\n",
    "        outputs = model(seqs, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "        loss = loss.mean()\n",
    "        total_loss += loss.item()\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward()\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "        #del seqs\n",
    "        #del labels\n",
    "        #del masks\n",
    "    avg_train_loss = total_loss / len(bucket_train_dataloader)\n",
    "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
    "    print(sample_text(model, tokenizer, text=predict_text))\n",
    "    torch.save({\n",
    "                'epoch': epoch+epo+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, os.path.join(model_dir , 'GPT2LMHeadModel_Finial.pt'))\n",
    "    if avg_train_loss < min_loss:\n",
    "        min_loss = avg_train_loss\n",
    "        torch.save({\n",
    "                'epoch': epoch+epo+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, os.path.join(model_dir , 'GPT2LMHeadModel_best.pt'))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8MiafZddiZM",
    "outputId": "a2e08f6c-6d80-4ea8-bef9-420a4732428d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D.O.B:  29/9/2000\n",
      "\n",
      "####\n",
      "\n",
      "<|endoftext|> Bid<|endoftext|> De<|endoftext|> T<|endoftext|> B<|endoftext|> D<|endoftext|> D<|endoftext|> H<|endoftext|> O<|endoftext|> Result<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "model_name = \"data/First_Phase_Release(Correction)/models/GPT2LMHeadModel\"\n",
    "# 模型儲存路徑\n",
    "model_dir = f\"{model_name}\"\n",
    "\n",
    "load_model = torch.load(os.path.join(model_dir , 'GPT2LMHeadModel_best.pt'))\n",
    "model.load_state_dict(load_model['model_state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "def sample_text(model, tokenizer, text, n_words=20):\n",
    "    model.eval()\n",
    "    text = tokenizer.encode(text)\n",
    "    inputs, past_key_values = torch.tensor([text]).to(device), None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_words):\n",
    "            out = model(inputs, past_key_values=past_key_values)\n",
    "            logits = out.logits\n",
    "            past_key_values = out.past_key_values\n",
    "            log_probs = F.softmax(logits[:, -1], dim=-1)\n",
    "            inputs = torch.multinomial(log_probs, 1)\n",
    "            text.append(inputs.item())\n",
    "            if tokenizer.decode(inputs.item()) == eos:\n",
    "                break\n",
    "\n",
    "    return tokenizer.decode(text)\n",
    "\n",
    "text = \"D.O.B:  29/9/2000\"\n",
    "print(sample_text(model, tokenizer, text=text , n_words=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpbgFWQn680B"
   },
   "outputs": [],
   "source": [
    "def process_valid_data(test_txts , out_file):\n",
    "    with open(out_file , 'w' , encoding = 'utf-8') as fw:\n",
    "        for txt in test_txts:\n",
    "            m_report = read_file(txt)\n",
    "            boundary = 0\n",
    "            # temp = ''.join(m_report)\n",
    "\n",
    "            # for Windows\n",
    "            fid = txt.split('\\\\')[-1].replace('.txt' , '')\n",
    "            \n",
    "            # for linux\n",
    "            # fid = txt.split('/')[-1].replace('.txt' , '')\n",
    "            \n",
    "            for idx,sent in enumerate(m_report):\n",
    "                if sent.replace(' ' , '').replace('\\n' , '').replace('\\t' , '') != '':\n",
    "                    sent = sent.replace('\\t' , ' ')\n",
    "                    fw.write(f\"{fid}\\t{boundary}\\t{sent}\\n\")\n",
    "                # else:\n",
    "                #     print(f\"{fid}\\t{boundary}\\t{sent}\\n\")\n",
    "                #     assert 1==2\n",
    "                boundary += len(sent)\n",
    "\n",
    "test_phase_path = r'data/First_Phase_Release(Correction)/Validation_Release'\n",
    "valid_out_file_path = './valid.tsv'\n",
    "test_txts = list(map(lambda x:os.path.join(test_phase_path , x) , os.listdir(test_phase_path)))\n",
    "test_txts = sorted(test_txts)\n",
    "valid_data = process_valid_data(test_txts , valid_out_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1G0sToC6vVS"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b585acfa3942688e1cef8e77881760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159cc08066964653b1cc3da01b607eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a486b6a88884b76a5ba615de29d357a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Features, Value\n",
    "valid_data = load_dataset(\"csv\", data_files=valid_out_file_path, delimiter='\\t',\n",
    "                          features = Features({\n",
    "                              'fid': Value('string'), 'idx': Value('int64'),\n",
    "                              'content': Value('string'), 'label': Value('string')}),\n",
    "                              column_names=['fid', 'idx', 'content', 'label'])\n",
    "valid_list= list(valid_data['train'])\n",
    "# valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMOuuV0jJcEc"
   },
   "outputs": [],
   "source": [
    "train_phi_category = ['PATIENT', 'DOCTOR', 'USERNAME',\n",
    "             'PROFESSION',\n",
    "             'ROOM', 'DEPARTMENT', 'HOSPITAL', 'ORGANIZATION', 'STREET', 'CITY', 'STATE', 'COUNTRY', 'ZIP', 'LOCATION-OTHER',\n",
    "             'AGE',\n",
    "             'DATE', 'TIME', 'DURATION', 'SET',\n",
    "             'PHONE', 'FAX', 'EMAIL', 'URL', 'IPADDR',\n",
    "             'SSN', 'MEDICALRECORD', 'HEALTHPLAN', 'ACCOUNT', 'LICENSE', 'VEHICLE', 'DEVICE', 'BIOID', 'IDNUM']\n",
    "\n",
    "'''\n",
    "pred 是一個字串，代表預測的文本或資訊。\n",
    "sep 是用來分隔文本的分隔符號。\n",
    "pad 是需要從文本中移除的填充符號。\n",
    "eos 是需要從文本中移除的結束符號。\n",
    "這行程式碼的執行步驟如下：\n",
    "\n",
    "pred.index(sep) 找到 sep 在 pred 中的索引位置。\n",
    "pred[pred.index(sep) + len(sep):] 從找到的索引位置之後的部分，即分隔符號後的文本。\n",
    ".replace(pad, \"\") 移除文本中的填充符號。\n",
    ".replace(eos, \"\") 移除文本中的結束符號。\n",
    ".strip() 移除文本兩側的空白字符。\n",
    "最終的結果存儲在 phi_infos 變數中。\n",
    "'''\n",
    "\n",
    "def get_anno_format(sentence , infos , boundary):\n",
    "    # 整行句子\n",
    "    # 預測的 PHI content\n",
    "    # 整行句子的起始位置\n",
    "    \n",
    "    anno_list = []\n",
    "    # lines = infos.split(\"\\n\") # 多個PHI type出現在同一行，{PHI type:PHI content\\nPHI type:PHI content\\n...}\n",
    "    lines = infos.split(\"   \")\n",
    "    \n",
    "    normalize_keys = ['DATE' , \"TIME\" , \"DURATION\" , \"SET\"]\n",
    "    phi_dict = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        # print(\"------------------------------------line：\\n\", line)\n",
    "\n",
    "        # 重要!!!\n",
    "        parts = line.split(\" QAQ \")\n",
    "        # print(\"------------------------------------parts(split line)：\\n\", parts)\n",
    "        \n",
    "        if parts[0] not in train_phi_category or parts[1] == '':\n",
    "            # print(\"有空的喔\")\n",
    "            continue\n",
    "\n",
    "        # 一行句子裡，只有一個 PHI content\n",
    "        # 重要!!!\n",
    "        if len(parts) == 2:\n",
    "            if parts[0] not in phi_dict:\n",
    "                phi_dict[parts[0]] = [parts[1].strip()]\n",
    "            else:\n",
    "                phi_dict[parts[0]].append(parts[1].strip())\n",
    "        # print(\"------------------------------------phi_dict：\\n\", phi_dict)\n",
    "\n",
    "    for phi_key, phi_values in phi_dict.items():\n",
    "        # 重要!!!(LIST)\n",
    "        for phi_value in phi_values:\n",
    "            # print(\"------------------------------------phi_key and phi_value：\\n{}\\n{}\".format(phi_key, phi_value))\n",
    "            # print(\"------------------------------------sentence：\\n\", sentence)\n",
    "            \n",
    "            normalize_time = None\n",
    "            \n",
    "            # 標準化時間項\n",
    "            if phi_key in normalize_keys:\n",
    "                if '=>' in phi_value:\n",
    "                    temp_phi_values = phi_value.split('=>')\n",
    "                    phi_value = temp_phi_values[0]\n",
    "                    normalize_time = temp_phi_values[-1]\n",
    "                else:\n",
    "                    normalize_time = phi_value\n",
    "    \n",
    "            \n",
    "            try:\n",
    "                matches = [(match.start(), match.end()) for match in re.finditer(phi_value, sentence)]\n",
    "            except:\n",
    "                continue\n",
    "            # print(\"------------------------------------matches：\\n\", matches)\n",
    "        \n",
    "            for start, end in matches:\n",
    "                if start == end:\n",
    "                    continue\n",
    "                item_dict = {\n",
    "                            'phi' : phi_key,\n",
    "                            'st_idx' : start + int(boundary),\n",
    "                            'ed_idx' : end + int(boundary),\n",
    "                            'entity' : phi_value,\n",
    "                }\n",
    "                \n",
    "                if normalize_time is not None:\n",
    "                    item_dict['normalize_time'] = normalize_time\n",
    "\n",
    "                # print(\"------------------------------------item_dict：\\n\", item_dict)\n",
    "\n",
    "                if item_dict not in anno_list:\n",
    "                    anno_list.append(item_dict) \n",
    "                    \n",
    "    return anno_list\n",
    "\n",
    "def aicup_predict(model, tokenizer, input, template = \"<|endoftext|> __CONTENT__\\n\\n####\\n\\n\"):\n",
    "    seeds = [template.replace(\"__CONTENT__\", data['content']) for data in input]\n",
    "    # print(\"------------------------------------Input seeds：\\n\", seeds)\n",
    "    \n",
    "    sep = tokenizer.sep_token\n",
    "    eos = tokenizer.eos_token\n",
    "    pad = tokenizer.pad_token\n",
    "    pad_idx = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "    \n",
    "    \"\"\"Generate text from a trained model.\"\"\"\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "    texts = tokenizer(seeds, return_tensors = 'pt', padding=True).to(device)\n",
    "    outputs = []\n",
    "    \n",
    "    with torch.cuda.amp.autocast():\n",
    "        output_tokens = model.generate(**texts, max_new_tokens=400, pad_token_id = pad_idx,\n",
    "                                        eos_token_id=tokenizer.convert_tokens_to_ids(eos))\n",
    "        \n",
    "        preds = tokenizer.batch_decode(output_tokens)\n",
    "        # print(\"------------------------------------preds：\\n\", preds)\n",
    "        \n",
    "        for idx , pred in enumerate(preds):\n",
    "            if \"NULL\" in pred:\n",
    "                continue\n",
    "\n",
    "            # print(\"------------------------------------pred：\\n\", pred)\n",
    "            \n",
    "            phi_infos = pred[pred.index(sep)+len(sep):].replace(pad, \"\").replace(bos, \"\").replace(eos, \"\").strip()\n",
    "            # print(\"------------------------------------phi_infos：\\n\", phi_infos)\n",
    "            \n",
    "            annotations = get_anno_format(input[idx]['content'] , phi_infos , input[idx]['idx'])\n",
    "            # print(\"------------------------------------annotations：\\n\", annotations)\n",
    "\n",
    "            for annotation in annotations:\n",
    "                if 'normalize_time' in annotation:\n",
    "                    outputs.append(f'{input[idx][\"fid\"]}\\t{annotation[\"phi\"]}\\t{annotation[\"st_idx\"]}\\t{annotation[\"ed_idx\"]}\\t{annotation[\"entity\"]}\\t{annotation[\"normalize_time\"]}')\n",
    "                else:\n",
    "                    outputs.append(f'{input[idx][\"fid\"]}\\t{annotation[\"phi\"]}\\t{annotation[\"st_idx\"]}\\t{annotation[\"ed_idx\"]}\\t{annotation[\"entity\"]}')\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from tqdm import tqdm\n",
    "\n",
    "# import io\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     seeds = [{'fid': '1066',\n",
    "#              'idx': 2266,\n",
    "#              'content': 'Tissue extremely difficult to dissociate and ?necrotic: regrettably, no mitoses were available for cytogenetic analysis.  Please advise the Laboratory (8382 9154) should interphase FISH be on paraffin-embedded tissue be of assistance in this case.',\n",
    "#              'label': None}]\n",
    "\n",
    "#     outputs = aicup_predict(model, tokenizer, input=seeds)\n",
    "#     for output in outputs:\n",
    "#         print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ae93341c50de44999cf0625aedbf3ef7",
      "5e5bec1be40b4ad29e25a57558f7cb6e",
      "8a303186a51d45dbaf12ecffe3290181",
      "3ac265a3464643f0aa4214cc8a158ad5",
      "984b289121d34cf09e53ab5259e7fa54",
      "fb23d5fb1ed84e889cf6a53af99c89f4",
      "28e1c0ac16a34c208dd6d522a55d2fef",
      "a884db9576b145739acdaed17ade04b7",
      "1f8cfd0e57fe4844a03d9bccff824bed",
      "8e3cb8283ff941a5b7d7824258f43888",
      "77fb282a840a49438b284b5453fe24c0"
     ]
    },
    "id": "RAtxuyFO8_kH",
    "outputId": "317e8fee-e194-45b9-d2bd-a3c8ece5444e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25739 [00:00<?, ?it/s]c:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "  0%|          | 30/25739 [00:17<4:13:30,  1.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\URay\\大學檔案\\大學三年級\\大三上\\資料探勘與應用\\資料探勘期末專題-隱私保護與醫學數據標準化競賽：解碼臨床病例、讓數據說故事\\test-Copy6 MBZUAILaMini-GPT-124M_v7.ipynb 儲存格 39\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/URay/%E5%A4%A7%E5%AD%B8%E6%AA%94%E6%A1%88/%E5%A4%A7%E5%AD%B8%E4%B8%89%E5%B9%B4%E7%B4%9A/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E8%88%87%E6%87%89%E7%94%A8/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E9%9A%B1%E7%A7%81%E4%BF%9D%E8%AD%B7%E8%88%87%E9%86%AB%E5%AD%B8%E6%95%B8%E6%93%9A%E6%A8%99%E6%BA%96%E5%8C%96%E7%AB%B6%E8%B3%BD%EF%BC%9A%E8%A7%A3%E7%A2%BC%E8%87%A8%E5%BA%8A%E7%97%85%E4%BE%8B%E3%80%81%E8%AE%93%E6%95%B8%E6%93%9A%E8%AA%AA%E6%95%85%E4%BA%8B/test-Copy6%20MBZUAILaMini-GPT-124M_v7.ipynb#X53sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/URay/%E5%A4%A7%E5%AD%B8%E6%AA%94%E6%A1%88/%E5%A4%A7%E5%AD%B8%E4%B8%89%E5%B9%B4%E7%B4%9A/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E8%88%87%E6%87%89%E7%94%A8/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E9%9A%B1%E7%A7%81%E4%BF%9D%E8%AD%B7%E8%88%87%E9%86%AB%E5%AD%B8%E6%95%B8%E6%93%9A%E6%A8%99%E6%BA%96%E5%8C%96%E7%AB%B6%E8%B3%BD%EF%BC%9A%E8%A7%A3%E7%A2%BC%E8%87%A8%E5%BA%8A%E7%97%85%E4%BE%8B%E3%80%81%E8%AE%93%E6%95%B8%E6%93%9A%E8%AA%AA%E6%95%85%E4%BA%8B/test-Copy6%20MBZUAILaMini-GPT-124M_v7.ipynb#X53sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     seeds \u001b[39m=\u001b[39m valid_list[i:i\u001b[39m+\u001b[39mBATCH_SIZE]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/URay/%E5%A4%A7%E5%AD%B8%E6%AA%94%E6%A1%88/%E5%A4%A7%E5%AD%B8%E4%B8%89%E5%B9%B4%E7%B4%9A/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E8%88%87%E6%87%89%E7%94%A8/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E9%9A%B1%E7%A7%81%E4%BF%9D%E8%AD%B7%E8%88%87%E9%86%AB%E5%AD%B8%E6%95%B8%E6%93%9A%E6%A8%99%E6%BA%96%E5%8C%96%E7%AB%B6%E8%B3%BD%EF%BC%9A%E8%A7%A3%E7%A2%BC%E8%87%A8%E5%BA%8A%E7%97%85%E4%BE%8B%E3%80%81%E8%AE%93%E6%95%B8%E6%93%9A%E8%AA%AA%E6%95%85%E4%BA%8B/test-Copy6%20MBZUAILaMini-GPT-124M_v7.ipynb#X53sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     outputs \u001b[39m=\u001b[39m aicup_predict(model, tokenizer, \u001b[39minput\u001b[39;49m \u001b[39m=\u001b[39;49m seeds)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/URay/%E5%A4%A7%E5%AD%B8%E6%AA%94%E6%A1%88/%E5%A4%A7%E5%AD%B8%E4%B8%89%E5%B9%B4%E7%B4%9A/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E8%88%87%E6%87%89%E7%94%A8/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E9%9A%B1%E7%A7%81%E4%BF%9D%E8%AD%B7%E8%88%87%E9%86%AB%E5%AD%B8%E6%95%B8%E6%93%9A%E6%A8%99%E6%BA%96%E5%8C%96%E7%AB%B6%E8%B3%BD%EF%BC%9A%E8%A7%A3%E7%A2%BC%E8%87%A8%E5%BA%8A%E7%97%85%E4%BE%8B%E3%80%81%E8%AE%93%E6%95%B8%E6%93%9A%E8%AA%AA%E6%95%85%E4%BA%8B/test-Copy6%20MBZUAILaMini-GPT-124M_v7.ipynb#X53sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m outputs:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/URay/%E5%A4%A7%E5%AD%B8%E6%AA%94%E6%A1%88/%E5%A4%A7%E5%AD%B8%E4%B8%89%E5%B9%B4%E7%B4%9A/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E8%88%87%E6%87%89%E7%94%A8/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E9%9A%B1%E7%A7%81%E4%BF%9D%E8%AD%B7%E8%88%87%E9%86%AB%E5%AD%B8%E6%95%B8%E6%93%9A%E6%A8%99%E6%BA%96%E5%8C%96%E7%AB%B6%E8%B3%BD%EF%BC%9A%E8%A7%A3%E7%A2%BC%E8%87%A8%E5%BA%8A%E7%97%85%E4%BE%8B%E3%80%81%E8%AE%93%E6%95%B8%E6%93%9A%E8%AA%AA%E6%95%85%E4%BA%8B/test-Copy6%20MBZUAILaMini-GPT-124M_v7.ipynb#X53sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         f\u001b[39m.\u001b[39mwrite(o)\n",
      "\u001b[1;32md:\\URay\\大學檔案\\大學三年級\\大三上\\資料探勘與應用\\資料探勘期末專題-隱私保護與醫學數據標準化競賽：解碼臨床病例、讓數據說故事\\test-Copy6 MBZUAILaMini-GPT-124M_v7.ipynb 儲存格 39\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/URay/%E5%A4%A7%E5%AD%B8%E6%AA%94%E6%A1%88/%E5%A4%A7%E5%AD%B8%E4%B8%89%E5%B9%B4%E7%B4%9A/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E8%88%87%E6%87%89%E7%94%A8/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E9%9A%B1%E7%A7%81%E4%BF%9D%E8%AD%B7%E8%88%87%E9%86%AB%E5%AD%B8%E6%95%B8%E6%93%9A%E6%A8%99%E6%BA%96%E5%8C%96%E7%AB%B6%E8%B3%BD%EF%BC%9A%E8%A7%A3%E7%A2%BC%E8%87%A8%E5%BA%8A%E7%97%85%E4%BE%8B%E3%80%81%E8%AE%93%E6%95%B8%E6%93%9A%E8%AA%AA%E6%95%85%E4%BA%8B/test-Copy6%20MBZUAILaMini-GPT-124M_v7.ipynb#X53sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m outputs \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/URay/%E5%A4%A7%E5%AD%B8%E6%AA%94%E6%A1%88/%E5%A4%A7%E5%AD%B8%E4%B8%89%E5%B9%B4%E7%B4%9A/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E8%88%87%E6%87%89%E7%94%A8/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E9%9A%B1%E7%A7%81%E4%BF%9D%E8%AD%B7%E8%88%87%E9%86%AB%E5%AD%B8%E6%95%B8%E6%93%9A%E6%A8%99%E6%BA%96%E5%8C%96%E7%AB%B6%E8%B3%BD%EF%BC%9A%E8%A7%A3%E7%A2%BC%E8%87%A8%E5%BA%8A%E7%97%85%E4%BE%8B%E3%80%81%E8%AE%93%E6%95%B8%E6%93%9A%E8%AA%AA%E6%95%85%E4%BA%8B/test-Copy6%20MBZUAILaMini-GPT-124M_v7.ipynb#X53sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast():\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/URay/%E5%A4%A7%E5%AD%B8%E6%AA%94%E6%A1%88/%E5%A4%A7%E5%AD%B8%E4%B8%89%E5%B9%B4%E7%B4%9A/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E8%88%87%E6%87%89%E7%94%A8/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E9%9A%B1%E7%A7%81%E4%BF%9D%E8%AD%B7%E8%88%87%E9%86%AB%E5%AD%B8%E6%95%B8%E6%93%9A%E6%A8%99%E6%BA%96%E5%8C%96%E7%AB%B6%E8%B3%BD%EF%BC%9A%E8%A7%A3%E7%A2%BC%E8%87%A8%E5%BA%8A%E7%97%85%E4%BE%8B%E3%80%81%E8%AE%93%E6%95%B8%E6%93%9A%E8%AA%AA%E6%95%85%E4%BA%8B/test-Copy6%20MBZUAILaMini-GPT-124M_v7.ipynb#X53sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m     output_tokens \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtexts, max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m400\u001b[39;49m, pad_token_id \u001b[39m=\u001b[39;49m pad_idx,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/URay/%E5%A4%A7%E5%AD%B8%E6%AA%94%E6%A1%88/%E5%A4%A7%E5%AD%B8%E4%B8%89%E5%B9%B4%E7%B4%9A/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E8%88%87%E6%87%89%E7%94%A8/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E9%9A%B1%E7%A7%81%E4%BF%9D%E8%AD%B7%E8%88%87%E9%86%AB%E5%AD%B8%E6%95%B8%E6%93%9A%E6%A8%99%E6%BA%96%E5%8C%96%E7%AB%B6%E8%B3%BD%EF%BC%9A%E8%A7%A3%E7%A2%BC%E8%87%A8%E5%BA%8A%E7%97%85%E4%BE%8B%E3%80%81%E8%AE%93%E6%95%B8%E6%93%9A%E8%AA%AA%E6%95%85%E4%BA%8B/test-Copy6%20MBZUAILaMini-GPT-124M_v7.ipynb#X53sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m                                     eos_token_id\u001b[39m=\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mconvert_tokens_to_ids(eos))\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/URay/%E5%A4%A7%E5%AD%B8%E6%AA%94%E6%A1%88/%E5%A4%A7%E5%AD%B8%E4%B8%89%E5%B9%B4%E7%B4%9A/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E8%88%87%E6%87%89%E7%94%A8/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E9%9A%B1%E7%A7%81%E4%BF%9D%E8%AD%B7%E8%88%87%E9%86%AB%E5%AD%B8%E6%95%B8%E6%93%9A%E6%A8%99%E6%BA%96%E5%8C%96%E7%AB%B6%E8%B3%BD%EF%BC%9A%E8%A7%A3%E7%A2%BC%E8%87%A8%E5%BA%8A%E7%97%85%E4%BE%8B%E3%80%81%E8%AE%93%E6%95%B8%E6%93%9A%E8%AA%AA%E6%95%85%E4%BA%8B/test-Copy6%20MBZUAILaMini-GPT-124M_v7.ipynb#X53sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m     preds \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mbatch_decode(output_tokens)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/URay/%E5%A4%A7%E5%AD%B8%E6%AA%94%E6%A1%88/%E5%A4%A7%E5%AD%B8%E4%B8%89%E5%B9%B4%E7%B4%9A/%E5%A4%A7%E4%B8%89%E4%B8%8A/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E8%88%87%E6%87%89%E7%94%A8/%E8%B3%87%E6%96%99%E6%8E%A2%E5%8B%98%E6%9C%9F%E6%9C%AB%E5%B0%88%E9%A1%8C-%E9%9A%B1%E7%A7%81%E4%BF%9D%E8%AD%B7%E8%88%87%E9%86%AB%E5%AD%B8%E6%95%B8%E6%93%9A%E6%A8%99%E6%BA%96%E5%8C%96%E7%AB%B6%E8%B3%BD%EF%BC%9A%E8%A7%A3%E7%A2%BC%E8%87%A8%E5%BA%8A%E7%97%85%E4%BE%8B%E3%80%81%E8%AE%93%E6%95%B8%E6%93%9A%E8%AA%AA%E6%95%85%E4%BA%8B/test-Copy6%20MBZUAILaMini-GPT-124M_v7.ipynb#X53sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m     \u001b[39m# print(\"------------------------------------preds：\\n\", preds)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1673\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1656\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massisted_decoding(\n\u001b[0;32m   1657\u001b[0m         input_ids,\n\u001b[0;32m   1658\u001b[0m         assistant_model\u001b[39m=\u001b[39massistant_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1669\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1670\u001b[0m     )\n\u001b[0;32m   1671\u001b[0m \u001b[39mif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGREEDY_SEARCH:\n\u001b[0;32m   1672\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[1;32m-> 1673\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[0;32m   1674\u001b[0m         input_ids,\n\u001b[0;32m   1675\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[0;32m   1676\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[0;32m   1677\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[0;32m   1678\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[0;32m   1679\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[0;32m   1680\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[0;32m   1681\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[0;32m   1682\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[0;32m   1683\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[0;32m   1684\u001b[0m     )\n\u001b[0;32m   1686\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[0;32m   1687\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:2521\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2518\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2520\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2521\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[0;32m   2522\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[0;32m   2523\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   2524\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   2525\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   2526\u001b[0m )\n\u001b[0;32m   2528\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2529\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1074\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1074\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[0;32m   1075\u001b[0m     input_ids,\n\u001b[0;32m   1076\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1077\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1078\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1079\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1080\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1081\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1082\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1083\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m   1084\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1085\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1086\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1087\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1089\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1091\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:888\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    876\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    877\u001b[0m         block\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[0;32m    878\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    885\u001b[0m         output_attentions,\n\u001b[0;32m    886\u001b[0m     )\n\u001b[0;32m    887\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[0;32m    889\u001b[0m         hidden_states,\n\u001b[0;32m    890\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    891\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    892\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[0;32m    893\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    894\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m    895\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    896\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    897\u001b[0m     )\n\u001b[0;32m    899\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    900\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:427\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    425\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m    426\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2(hidden_states)\n\u001b[1;32m--> 427\u001b[0m feed_forward_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(hidden_states)\n\u001b[0;32m    428\u001b[0m \u001b[39m# residual connection\u001b[39;00m\n\u001b[0;32m    429\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:356\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    354\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_fc(hidden_states)\n\u001b[0;32m    355\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(hidden_states)\n\u001b[1;32m--> 356\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc_proj(hidden_states)\n\u001b[0;32m    357\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    358\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\longy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pytorch_utils.py:107\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    106\u001b[0m     size_out \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnf,)\n\u001b[1;32m--> 107\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49maddmm(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, x\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, x\u001b[39m.\u001b[39;49msize(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)\n\u001b[0;32m    108\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(size_out)\n\u001b[0;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import io\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "with open(\"./answer.txt\", 'w', encoding='utf8') as f:\n",
    "    for i in tqdm(range(0, len(valid_list), BATCH_SIZE)):\n",
    "        with torch.no_grad():\n",
    "            seeds = valid_list[i:i+BATCH_SIZE]\n",
    "            outputs = aicup_predict(model, tokenizer, input = seeds)\n",
    "            for o in outputs:\n",
    "                f.write(o)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0277cbac4f0744d0a2460ede86d1ad33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "02fdb917569740c2a15ce78df9fe9f0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_351429ff2f4d4f1185fed17d49c2df55",
       "IPY_MODEL_29c3341b98ed45cebe9768a1cee61789",
       "IPY_MODEL_240e4fbdac7a4783b7b1a265f827b8e6"
      ],
      "layout": "IPY_MODEL_cd395bc5ef7347059cc3967f293e9cb4"
     }
    },
    "04f5241d1ed74346a6e079f20b0e1c86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06a3d8b0210642098a789cabcd9fe946",
      "placeholder": "​",
      "style": "IPY_MODEL_9c743c15b86d4f19834b933fe4147920",
      "value": "Downloading data files: 100%"
     }
    },
    "06a3d8b0210642098a789cabcd9fe946": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b1e56e88a584720a0a3491ac11050bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c9d57ad1dfc458e9ddb25692f881976": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_114be4b208be40e0a17ddee4e046fb23",
      "placeholder": "​",
      "style": "IPY_MODEL_3664935430614c24bd7f5c4e3b2e04c6",
      "value": " 99.0/99.0 [00:00&lt;00:00, 6.11kB/s]"
     }
    },
    "114be4b208be40e0a17ddee4e046fb23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12c9de0d18844719ab9b1a19876c77e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66f51dc7be3a453099a82a17731c136a",
      "placeholder": "​",
      "style": "IPY_MODEL_9b5ca4c8b80e4b59a3ea6535c73449c5",
      "value": "Downloading (…)cial_tokens_map.json: 100%"
     }
    },
    "138978af73d44cddb6b42165f50616a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa23352bc7864a38ab8c52ae1f8f15ca",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_edd98b31b60f48d395a3b9f35e0cb15e",
      "value": 1
     }
    },
    "15a75326cb3446639f6476175594f674": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2baeb275db84ee2be09ad54cba4b557",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ebc555d2bdf542208af547b35f098e0f",
      "value": 1
     }
    },
    "1c12b7a726904fd28f3722a73f8aed46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d8908777f5246b5b0a47708e7b92c2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f8cfd0e57fe4844a03d9bccff824bed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "240e4fbdac7a4783b7b1a265f827b8e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ed3fe215482424ca313941bf4999131",
      "placeholder": "​",
      "style": "IPY_MODEL_847104cbfe6c447e8f3e6cf789c1860d",
      "value": " 1/1 [00:00&lt;00:00, 35.87it/s]"
     }
    },
    "262d64b395eb438e80749d5447043f6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28e1c0ac16a34c208dd6d522a55d2fef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29c3341b98ed45cebe9768a1cee61789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d8908777f5246b5b0a47708e7b92c2a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8c235594ea04894b7ae7045069b6b71",
      "value": 1
     }
    },
    "2ed3fe215482424ca313941bf4999131": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "351429ff2f4d4f1185fed17d49c2df55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c34d081bc24a477ca2a9033fb5ac96e0",
      "placeholder": "​",
      "style": "IPY_MODEL_0277cbac4f0744d0a2460ede86d1ad33",
      "value": "Extracting data files: 100%"
     }
    },
    "35b763e2220d47f888dd532d929b91c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35e624622fc7427e9e3e9ce06ff69b13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "364c458247d3493eb836d163204e7c44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc80bd4f3e9b40f7901387ffb92c9af2",
      "placeholder": "​",
      "style": "IPY_MODEL_eb7955e3b9bd491d9a170a6410991603",
      "value": "Generating train split: "
     }
    },
    "3664935430614c24bd7f5c4e3b2e04c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ab10d53358341c08bdb473b60a987ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_04f5241d1ed74346a6e079f20b0e1c86",
       "IPY_MODEL_15a75326cb3446639f6476175594f674",
       "IPY_MODEL_a8d3a2563e93469282d2aa1254c8a709"
      ],
      "layout": "IPY_MODEL_dd4aae35778245dcb85cc3bfaeeab2cb"
     }
    },
    "3ac265a3464643f0aa4214cc8a158ad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e3cb8283ff941a5b7d7824258f43888",
      "placeholder": "​",
      "style": "IPY_MODEL_77fb282a840a49438b284b5453fe24c0",
      "value": " 2680/2680 [08:55&lt;00:00,  7.84it/s]"
     }
    },
    "3efa4f1535c04dc6853d08d760e53f10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c912f23ed4341e9bf76ca5d0b0d1c6d",
      "max": 99,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a17d608a377c4fe7803d7df82a2a1e4b",
      "value": 99
     }
    },
    "4131050ae1db4ec59e28043b263edee4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4583193cd4d2416f891d79e3f6574ae1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "477487bd5dd54a789eb3d8a421b848d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "48849553f92a403e81a32572edadf54b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c912f23ed4341e9bf76ca5d0b0d1c6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d7d64eecd1c43c0b93df2b5580a3089": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_541b410749e64a1898b689a71fdcd190",
       "IPY_MODEL_a699553a035245faa229208847d769c1",
       "IPY_MODEL_905fbcece64f4a44a16e0bc230212809"
      ],
      "layout": "IPY_MODEL_fc9c2553ba8a48dd9a8a24ab58a3712c"
     }
    },
    "53eb2f1db30643b892f2fb0de4e462e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4583193cd4d2416f891d79e3f6574ae1",
      "placeholder": "​",
      "style": "IPY_MODEL_74c075f1555c40c4acef391e7ebd607a",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "541b410749e64a1898b689a71fdcd190": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_930ae3d226c84d39b7e99ba2094d13de",
      "placeholder": "​",
      "style": "IPY_MODEL_6b4e1cd915dc4467a383f595c97428c9",
      "value": "Downloading (…)p3000/tokenizer.json: 100%"
     }
    },
    "57b70738c47d4c46b11ec8d9f3da8002": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5906da6ef4cb493fa69981791169ba6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e5bec1be40b4ad29e25a57558f7cb6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb23d5fb1ed84e889cf6a53af99c89f4",
      "placeholder": "​",
      "style": "IPY_MODEL_28e1c0ac16a34c208dd6d522a55d2fef",
      "value": "100%"
     }
    },
    "620547130fe8427587389ffd8605242e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66f51dc7be3a453099a82a17731c136a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "699293e978ee4e03a29873ab1aa5584a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4131050ae1db4ec59e28043b263edee4",
      "placeholder": "​",
      "style": "IPY_MODEL_35b763e2220d47f888dd532d929b91c1",
      "value": " 396/396 [00:00&lt;00:00, 21.2kB/s]"
     }
    },
    "6a2e7073e6244df590aebaef7a22fcbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b4e1cd915dc4467a383f595c97428c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "716ec33c9d4444468922a4515c861bfd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74c075f1555c40c4acef391e7ebd607a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "771c433a517f4d5caefe3d1a5ab6dbd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_262d64b395eb438e80749d5447043f6c",
      "max": 396,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_477487bd5dd54a789eb3d8a421b848d2",
      "value": 396
     }
    },
    "77fb282a840a49438b284b5453fe24c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c8b111c35ed4795b299d8b4a9a677e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_12c9de0d18844719ab9b1a19876c77e0",
       "IPY_MODEL_3efa4f1535c04dc6853d08d760e53f10",
       "IPY_MODEL_0c9d57ad1dfc458e9ddb25692f881976"
      ],
      "layout": "IPY_MODEL_bc5c0b0bb22b46979526f4ee320f3154"
     }
    },
    "7d4e0e0b68b14aee9ba6060c88e8fbe7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82d3f122e8344078b2f59c8992d318d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "847104cbfe6c447e8f3e6cf789c1860d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a303186a51d45dbaf12ecffe3290181": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a884db9576b145739acdaed17ade04b7",
      "max": 2680,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f8cfd0e57fe4844a03d9bccff824bed",
      "value": 2680
     }
    },
    "8d44ecffa2f045f0bab7d5c1f3722ac1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa22a2d4c9254284ab8e20e85cf6a1dd",
       "IPY_MODEL_99d41ec930c84fb485167dce8d6453d4",
       "IPY_MODEL_8fdb40e1334a407482b3e023a593d697"
      ],
      "layout": "IPY_MODEL_48849553f92a403e81a32572edadf54b"
     }
    },
    "8e3cb8283ff941a5b7d7824258f43888": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fdb40e1334a407482b3e023a593d697": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_716ec33c9d4444468922a4515c861bfd",
      "placeholder": "​",
      "style": "IPY_MODEL_0b1e56e88a584720a0a3491ac11050bb",
      "value": " 166M/166M [00:02&lt;00:00, 62.1MB/s]"
     }
    },
    "905fbcece64f4a44a16e0bc230212809": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d03ce9716d884221828cdf8f522c7b23",
      "placeholder": "​",
      "style": "IPY_MODEL_1c12b7a726904fd28f3722a73f8aed46",
      "value": " 2.11M/2.11M [00:00&lt;00:00, 10.3MB/s]"
     }
    },
    "930ae3d226c84d39b7e99ba2094d13de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93839d2cb8eb47e98bde3cc6ea26be61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95f62323efb74a5fbc8eeea96fde205f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_53eb2f1db30643b892f2fb0de4e462e0",
       "IPY_MODEL_771c433a517f4d5caefe3d1a5ab6dbd5",
       "IPY_MODEL_699293e978ee4e03a29873ab1aa5584a"
      ],
      "layout": "IPY_MODEL_9881ffc1fe1f4d42ad86a434de5630c3"
     }
    },
    "984b289121d34cf09e53ab5259e7fa54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9881ffc1fe1f4d42ad86a434de5630c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99d41ec930c84fb485167dce8d6453d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82d3f122e8344078b2f59c8992d318d1",
      "max": 166049099,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc45d04b5f8b4e84ae99b5406a8a8d8d",
      "value": 166049099
     }
    },
    "9b5ca4c8b80e4b59a3ea6535c73449c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c743c15b86d4f19834b933fe4147920": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a17d608a377c4fe7803d7df82a2a1e4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a250ec3f4bb043688fe9a74a85ae622e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a699553a035245faa229208847d769c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93839d2cb8eb47e98bde3cc6ea26be61",
      "max": 2113710,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5a12d27ad8d4b928225fec745838bb8",
      "value": 2113710
     }
    },
    "a884db9576b145739acdaed17ade04b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8d3a2563e93469282d2aa1254c8a709": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed64e4b7931d4e80bd1b830e9ab4589a",
      "placeholder": "​",
      "style": "IPY_MODEL_d6084e8cbf9e4afea588776c60058b44",
      "value": " 1/1 [00:00&lt;00:00, 50.82it/s]"
     }
    },
    "aa22a2d4c9254284ab8e20e85cf6a1dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_620547130fe8427587389ffd8605242e",
      "placeholder": "​",
      "style": "IPY_MODEL_35e624622fc7427e9e3e9ce06ff69b13",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "ae93341c50de44999cf0625aedbf3ef7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e5bec1be40b4ad29e25a57558f7cb6e",
       "IPY_MODEL_8a303186a51d45dbaf12ecffe3290181",
       "IPY_MODEL_3ac265a3464643f0aa4214cc8a158ad5"
      ],
      "layout": "IPY_MODEL_984b289121d34cf09e53ab5259e7fa54"
     }
    },
    "bc5c0b0bb22b46979526f4ee320f3154": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd858ddc900540d39319402f576a6146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5906da6ef4cb493fa69981791169ba6f",
      "placeholder": "​",
      "style": "IPY_MODEL_d91b672aab19468a8f9ba084c9181705",
      "value": " 53213/0 [00:00&lt;00:00, 197292.05 examples/s]"
     }
    },
    "c34d081bc24a477ca2a9033fb5ac96e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c47491ab567c4aa6ad6da05329d5b570": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc83a2f4b0964878a6c3a77018288a46",
      "max": 567,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_57b70738c47d4c46b11ec8d9f3da8002",
      "value": 567
     }
    },
    "c5a12d27ad8d4b928225fec745838bb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc80bd4f3e9b40f7901387ffb92c9af2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd395bc5ef7347059cc3967f293e9cb4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cee85f4100e04283b6276653174ae667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d03ce9716d884221828cdf8f522c7b23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6084e8cbf9e4afea588776c60058b44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7f1fd5dafe143d58b383865f2520892": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d91b672aab19468a8f9ba084c9181705": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc45d04b5f8b4e84ae99b5406a8a8d8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dd4aae35778245dcb85cc3bfaeeab2cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e765ef2c16a244cbba8afd58f0b19bc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_364c458247d3493eb836d163204e7c44",
       "IPY_MODEL_138978af73d44cddb6b42165f50616a1",
       "IPY_MODEL_bd858ddc900540d39319402f576a6146"
      ],
      "layout": "IPY_MODEL_6a2e7073e6244df590aebaef7a22fcbc"
     }
    },
    "eb7955e3b9bd491d9a170a6410991603": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ebc555d2bdf542208af547b35f098e0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ed64e4b7931d4e80bd1b830e9ab4589a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edd98b31b60f48d395a3b9f35e0cb15e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2baeb275db84ee2be09ad54cba4b557": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f704f11641774603b4d5319580fbb994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f76695b96069401e938c52e75430ea1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d4e0e0b68b14aee9ba6060c88e8fbe7",
      "placeholder": "​",
      "style": "IPY_MODEL_cee85f4100e04283b6276653174ae667",
      "value": " 567/567 [00:00&lt;00:00, 24.8kB/s]"
     }
    },
    "f8c235594ea04894b7ae7045069b6b71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa23352bc7864a38ab8c52ae1f8f15ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "fb23d5fb1ed84e889cf6a53af99c89f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc83a2f4b0964878a6c3a77018288a46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc9c2553ba8a48dd9a8a24ab58a3712c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcd1dd3df93040578f33ba79cbc79464": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7f1fd5dafe143d58b383865f2520892",
      "placeholder": "​",
      "style": "IPY_MODEL_a250ec3f4bb043688fe9a74a85ae622e",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "fd8483f4d5f541ca89bcdb48e83aa262": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fcd1dd3df93040578f33ba79cbc79464",
       "IPY_MODEL_c47491ab567c4aa6ad6da05329d5b570",
       "IPY_MODEL_f76695b96069401e938c52e75430ea1e"
      ],
      "layout": "IPY_MODEL_f704f11641774603b4d5319580fbb994"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
